"""
ä¾§è¾¹æ ç»„ä»¶
"""

import streamlit as st
import os
import logging
import sys
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from web.utils.persistence import load_model_selection, save_model_selection
from web.utils.model_fetcher import model_fetcher

logger = logging.getLogger(__name__)

def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ é…ç½®"""

    # æ·»åŠ localStorageæ”¯æŒçš„JavaScript
    st.markdown("""
    <script>
    // ä¿å­˜åˆ°localStorage
    function saveToLocalStorage(key, value) {
        localStorage.setItem('tradingagents_' + key, value);
        console.log('Saved to localStorage:', key, value);
    }

    // ä»localStorageè¯»å–
    function loadFromLocalStorage(key, defaultValue) {
        const value = localStorage.getItem('tradingagents_' + key);
        console.log('Loaded from localStorage:', key, value || defaultValue);
        return value || defaultValue;
    }

    // é¡µé¢åŠ è½½æ—¶æ¢å¤è®¾ç½®
    window.addEventListener('load', function() {
        console.log('Page loaded, restoring settings...');
    });
    </script>
    """, unsafe_allow_html=True)

    # ä¼˜åŒ–ä¾§è¾¹æ æ ·å¼
    st.markdown("""
    <style>
    /* ä¼˜åŒ–ä¾§è¾¹æ å®½åº¦ - è°ƒæ•´ä¸º320px */
    section[data-testid="stSidebar"] {
        width: 320px !important;
        min-width: 320px !important;
        max-width: 320px !important;
    }

    /* ä¼˜åŒ–ä¾§è¾¹æ å†…å®¹å®¹å™¨ */
    section[data-testid="stSidebar"] > div {
        width: 320px !important;
        min-width: 320px !important;
        max-width: 320px !important;
    }

    /* å¼ºåˆ¶å‡å°‘ä¾§è¾¹æ å†…è¾¹è· - å¤šç§é€‰æ‹©å™¨ç¡®ä¿ç”Ÿæ•ˆ */
    section[data-testid="stSidebar"] .block-container,
    section[data-testid="stSidebar"] > div > div,
    .css-1d391kg,
    .css-1lcbmhc,
    .css-1cypcdb {
        padding-top: 0.75rem !important;
        padding-left: 0.5rem !important;
        padding-right: 0.5rem !important;
        padding-bottom: 0.75rem !important;
    }

    /* ä¾§è¾¹æ å†…æ‰€æœ‰å…ƒç´ çš„è¾¹è·æ§åˆ¶ */
    section[data-testid="stSidebar"] * {
        box-sizing: border-box !important;
    }

    /* ä¼˜åŒ–selectboxå®¹å™¨ */
    section[data-testid="stSidebar"] .stSelectbox {
        margin-bottom: 0.4rem !important;
        width: 100% !important;
    }

    /* ä¼˜åŒ–selectboxä¸‹æ‹‰æ¡† - è°ƒæ•´ä¸ºé€‚åˆ320px */
    section[data-testid="stSidebar"] .stSelectbox > div > div,
    section[data-testid="stSidebar"] .stSelectbox [data-baseweb="select"] {
        width: 100% !important;
        min-width: 260px !important;
        max-width: 280px !important;
    }

    /* ä¼˜åŒ–ä¸‹æ‹‰æ¡†é€‰é¡¹æ–‡æœ¬ */
    section[data-testid="stSidebar"] .stSelectbox label {
        font-size: 0.85rem !important;
        font-weight: 600 !important;
        margin-bottom: 0.2rem !important;
    }

    /* ä¼˜åŒ–æ–‡æœ¬è¾“å…¥æ¡† */
    section[data-testid="stSidebar"] .stTextInput > div > div > input {
        font-size: 0.8rem !important;
        padding: 0.3rem 0.5rem !important;
        width: 100% !important;
    }

    /* ä¼˜åŒ–æŒ‰é’®æ ·å¼ */
    section[data-testid="stSidebar"] .stButton > button {
        width: 100% !important;
        font-size: 0.8rem !important;
        padding: 0.3rem 0.5rem !important;
        margin: 0.1rem 0 !important;
        border-radius: 0.3rem !important;
    }

    /* ä¼˜åŒ–æ ‡é¢˜æ ·å¼ */
    section[data-testid="stSidebar"] h3 {
        font-size: 1rem !important;
        margin-bottom: 0.5rem !important;
        margin-top: 0.3rem !important;
        padding: 0 !important;
    }

    /* ä¼˜åŒ–infoæ¡†æ ·å¼ */
    section[data-testid="stSidebar"] .stAlert {
        padding: 0.4rem !important;
        margin: 0.3rem 0 !important;
        font-size: 0.75rem !important;
    }

    /* ä¼˜åŒ–æ–‡æœ¬ */
    section[data-testid="stSidebar"] .stMarkdown {
        margin-bottom: 0.3rem !important;
        padding: 0 !important;
    }

    /* ä¼˜åŒ–åˆ†éš”çº¿ */
    section[data-testid="stSidebar"] hr {
        margin: 0.75rem 0 !important;
    }

    /* ç¡®ä¿ä¸‹æ‹‰æ¡†é€‰é¡¹å®Œå…¨å¯è§ - è°ƒæ•´ä¸ºé€‚åˆ320px */
    .stSelectbox [data-baseweb="select"] {
        min-width: 260px !important;
        max-width: 280px !important;
    }

    /* ä¼˜åŒ–ä¸‹æ‹‰æ¡†é€‰é¡¹åˆ—è¡¨ */
    .stSelectbox [role="listbox"] {
        min-width: 260px !important;
        max-width: 290px !important;
    }

    /* é¢å¤–çš„è¾¹è·æ§åˆ¶ - ç¡®ä¿å·¦å³è¾¹è·å‡å° */
    .sidebar .element-container {
        padding: 0 !important;
        margin: 0.2rem 0 !important;
    }

    /* å¼ºåˆ¶è¦†ç›–é»˜è®¤æ ·å¼ */
    .css-1d391kg .element-container {
        padding-left: 0.5rem !important;
        padding-right: 0.5rem !important;
    }
    </style>
    """, unsafe_allow_html=True)

    with st.sidebar:
        # ä½¿ç”¨ç»„ä»¶æ¥ä»localStorageè¯»å–å¹¶åˆå§‹åŒ–session state
        st.markdown("""
        <div id="localStorage-reader" style="display: none;">
            <script>
            // ä»localStorageè¯»å–è®¾ç½®å¹¶å‘é€ç»™Streamlit
            const provider = loadFromLocalStorage('llm_provider', 'dashscope');
            const category = loadFromLocalStorage('model_category', 'openai');
            const model = loadFromLocalStorage('llm_model', '');

            // é€šè¿‡è‡ªå®šä¹‰äº‹ä»¶å‘é€æ•°æ®
            window.parent.postMessage({
                type: 'localStorage_data',
                provider: provider,
                category: category,
                model: model
            }, '*');
            </script>
        </div>
        """, unsafe_allow_html=True)

        # ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½é…ç½®
        saved_config = load_model_selection()

        # åˆå§‹åŒ–session stateï¼Œä¼˜å…ˆä½¿ç”¨ä¿å­˜çš„é…ç½®
        if 'llm_provider' not in st.session_state:
            st.session_state.llm_provider = saved_config['provider']
            logger.debug(f"ğŸ”§ [Persistence] æ¢å¤ llm_provider: {st.session_state.llm_provider}")
        if 'model_category' not in st.session_state:
            st.session_state.model_category = saved_config['category']
            logger.debug(f"ğŸ”§ [Persistence] æ¢å¤ model_category: {st.session_state.model_category}")
        if 'llm_model' not in st.session_state:
            st.session_state.llm_model = saved_config['model']
            logger.debug(f"ğŸ”§ [Persistence] æ¢å¤ llm_model: {st.session_state.llm_model}")

        # æ˜¾ç¤ºå½“å‰session stateçŠ¶æ€ï¼ˆè°ƒè¯•ç”¨ï¼‰
        logger.debug(f"ğŸ” [Session State] å½“å‰çŠ¶æ€ - provider: {st.session_state.llm_provider}, category: {st.session_state.model_category}, model: {st.session_state.llm_model}")

        # AIæ¨¡å‹é…ç½®ï¼ˆåŠ¨æ€é€‰æ‹©ï¼‰
        st.markdown("### ğŸ§  AIæ¨¡å‹é…ç½®")
        
        # è®¾ç½®å›ºå®šçš„æä¾›å•†é…ç½®
        st.session_state.llm_provider = 'openai'
        st.session_state.model_category = 'openai'
        
        # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
        with st.spinner("æ­£åœ¨è·å–å¯ç”¨æ¨¡å‹..."):
            available_models = model_fetcher.get_available_models()
        
        if available_models:
            # è·å–é»˜è®¤æ¨¡å‹
            default_model = model_fetcher.get_default_model()
            
            # å¦‚æœsession stateä¸­æ²¡æœ‰æ¨¡å‹æˆ–æ¨¡å‹ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
            if 'llm_model' not in st.session_state or st.session_state.llm_model not in available_models:
                st.session_state.llm_model = default_model
            
            # æ¨¡å‹é€‰æ‹©å™¨
            col1, col2 = st.columns([4, 1])
            
            with col1:
                selected_model = st.selectbox(
                    "ğŸš€ é€‰æ‹©AIæ¨¡å‹",
                    options=available_models,
                    index=available_models.index(st.session_state.llm_model) if st.session_state.llm_model in available_models else 0,
                    key="model_selector",
                    help="ä»å¯ç”¨æ¨¡å‹åˆ—è¡¨ä¸­é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
                )
                
                # æ›´æ–°session state
                if selected_model != st.session_state.llm_model:
                    st.session_state.llm_model = selected_model
                    logger.info(f"ğŸ”„ ç”¨æˆ·åˆ‡æ¢æ¨¡å‹åˆ°: {selected_model}")
                    # ä¿å­˜é…ç½®
                    save_model_selection(st.session_state.llm_provider, st.session_state.model_category, st.session_state.llm_model)
            
            with col2:
                if st.button("ğŸ”„", help="åˆ·æ–°æ¨¡å‹åˆ—è¡¨"):
                    model_fetcher.refresh_models()
                    st.rerun()
            
            # æ˜¾ç¤ºå½“å‰æ¨¡å‹ä¿¡æ¯
            st.success(f"âœ… **å½“å‰æ¨¡å‹**: {st.session_state.llm_model}")
            
            with st.expander("ğŸ“‹ æ¨¡å‹é…ç½®è¯¦æƒ…", expanded=False):
                st.markdown(f"""
                **å½“å‰æ¨¡å‹é…ç½®ï¼š**
                - ğŸ¯ **æä¾›å•†**ï¼šç¬¬ä¸‰æ–¹OpenAIå…¼å®¹æœåŠ¡
                - ğŸš€ **æ¨¡å‹**ï¼š{st.session_state.llm_model}
                - ğŸŒ **APIç«¯ç‚¹**ï¼šhttps://llm.submodel.ai/v1
                - ğŸ“Š **å¯ç”¨æ¨¡å‹æ•°**ï¼š{len(available_models)}
                - ğŸ’° **ç‰¹ç‚¹**ï¼šé«˜æ€§ä»·æ¯”ï¼Œå“åº”å¿«é€Ÿï¼Œå¤šæ¨¡å‹é€‰æ‹©
                """)
            
            # Tokenä»·æ ¼é…ç½®
            render_token_pricing_config()
        else:
            # å¦‚æœè·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥ï¼Œå›é€€åˆ°å›ºå®šé…ç½®
            st.warning("âš ï¸ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            st.session_state.llm_model = 'deepseek-ai/DeepSeek-V3.1'
            st.info(f"ğŸš€ **é»˜è®¤æ¨¡å‹**: {st.session_state.llm_model}")
        
        # æ£€æŸ¥APIå¯†é’¥é…ç½®çŠ¶æ€
        import os
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key and api_key.startswith('sk-'):
            # å®‰å…¨åœ°æ˜¾ç¤ºAPIå¯†é’¥ï¼ˆå¤„ç†SecretStrç±»å‹ï¼‰
            if hasattr(api_key, 'get_secret_value'):
                key_display = api_key.get_secret_value()[:20] if api_key.get_secret_value() else 'None'
            else:
                key_display = str(api_key)[:20] if api_key else 'None'
            st.success(f"âœ… APIå¯†é’¥å·²é…ç½®ï¼š{key_display}...")
        else:
            st.error("âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®OPENAI_API_KEY")
            st.code("OPENAI_API_KEY=sk-84erLIZj6ljBXra9BPC77mWqfNC7sxI2P7MhbVuiWcEKl4Rq")
        
        # ä¿å­˜é…ç½®åˆ°æŒä¹…åŒ–å­˜å‚¨ï¼ˆä¸ºäº†å…¼å®¹æ€§ï¼‰
        save_model_selection(st.session_state.llm_provider, st.session_state.model_category, st.session_state.llm_model)

        st.markdown("---")
        
        # ç³»ç»Ÿé…ç½®
        st.markdown("**ğŸ”§ ç³»ç»Ÿé…ç½®**")

        # APIå¯†é’¥çŠ¶æ€
        st.markdown("**ğŸ”‘ APIå¯†é’¥çŠ¶æ€**")

        def validate_api_key(key, expected_format):
            """éªŒè¯APIå¯†é’¥æ ¼å¼"""
            if not key:
                return "æœªé…ç½®", "error"

            if expected_format == "openai" and key.startswith("sk-") and len(key) >= 40:
                return f"{key[:20]}...", "success"
            elif expected_format == "finnhub" and len(key) >= 20:
                return f"{key[:8]}...", "success"
            else:
                return f"{key[:8]}... (æ ¼å¼å¼‚å¸¸)", "warning"

        # å¿…éœ€çš„APIå¯†é’¥
        st.markdown("*å¿…éœ€é…ç½®:*")

        # OpenAI APIå¯†é’¥ (ç”¨äºDeepSeek)
        openai_key = os.getenv("OPENAI_API_KEY")
        status, level = validate_api_key(openai_key, "openai")
        if level == "success":
            st.success(f"âœ… OpenAI API (DeepSeek): {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ OpenAI API (DeepSeek): {status}")
        else:
            st.error("âŒ OpenAI API (DeepSeek): æœªé…ç½®")
            st.code("OPENAI_API_KEY=sk-84erLIZj6ljBXra9BPC77mWqfNC7sxI2P7MhbVuiWcEKl4Rq")

        # FinnHub
        finnhub_key = os.getenv("FINNHUB_API_KEY")
        status, level = validate_api_key(finnhub_key, "finnhub")
        if level == "success":
            st.success(f"âœ… FinnHub: {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ FinnHub: {status}")
        else:
            st.error("âŒ FinnHub: æœªé…ç½®")

        st.markdown("---")

        # ç³»ç»Ÿä¿¡æ¯
        st.markdown("**â„¹ï¸ ç³»ç»Ÿä¿¡æ¯**")
        
        st.info(f"""
        **ç‰ˆæœ¬**: cn-0.1.13
        **æ¡†æ¶**: Streamlit + LangGraph
        **AIæ¨¡å‹**: {st.session_state.llm_provider.upper()} - {st.session_state.llm_model}
        **æ•°æ®æº**: Tushare + FinnHub API
        """)
        
        # å¸®åŠ©é“¾æ¥
        st.markdown("**ğŸ“š å¸®åŠ©èµ„æº**")
        
        st.markdown("""
        - [ğŸ“– ä½¿ç”¨æ–‡æ¡£](https://github.com/TauricResearch/TradingAgents)
        - [ğŸ› é—®é¢˜åé¦ˆ](https://github.com/TauricResearch/TradingAgents/issues)
        - [ğŸ’¬ è®¨è®ºç¤¾åŒº](https://github.com/TauricResearch/TradingAgents/discussions)
        - [ğŸ”§ APIå¯†é’¥é…ç½®](../docs/security/api_keys_security.md)
        """)
    
    # ç¡®ä¿è¿”å›session stateä¸­çš„å€¼ï¼Œè€Œä¸æ˜¯å±€éƒ¨å˜é‡
    final_provider = st.session_state.llm_provider
    final_model = st.session_state.llm_model

    logger.debug(f"ğŸ”„ [Session State] è¿”å›é…ç½® - provider: {final_provider}, model: {final_model}")

    # å›ºå®šç³»ç»Ÿé…ç½®å€¼
    enable_memory = False  # ç®€åŒ–é…ç½®ï¼Œå…³é—­è®°å¿†åŠŸèƒ½
    enable_debug = False   # ç®€åŒ–é…ç½®ï¼Œå…³é—­è°ƒè¯•æ¨¡å¼
    max_tokens = 4096      # é»˜è®¤tokené™åˆ¶
    
    return {
        'llm_provider': final_provider,
        'llm_model': final_model,
        'enable_memory': enable_memory,
        'enable_debug': enable_debug,
        'max_tokens': max_tokens
    }


def render_token_pricing_config():
    """æ¸²æŸ“ç®€åŒ–çš„Tokenä»·æ ¼é…ç½®"""
    
    st.markdown("**ğŸ’° Tokenä»·æ ¼é…ç½®**")
    
    # åŠ è½½å½“å‰é…ç½®
    pricing_config = load_token_pricing_config()
    
    # åˆ›å»ºé…ç½®è¡¨å•
    with st.form("token_pricing_form"):
        st.markdown("*é…ç½®Tokenä»·æ ¼ï¼ˆæ¯1000ä¸ªtokençš„ä»·æ ¼ï¼Œå•ä½ï¼šÂ¥ï¼‰*")
        
        col1, col2 = st.columns(2)
        with col1:
            input_price = st.number_input(
                "è¾“å…¥ä»·æ ¼ (Â¥/1K tokens)",
                value=pricing_config.get("input_price", 0.002),
                min_value=0.0,
                max_value=1.0,
                step=0.0001,
                format="%.4f",
                key="token_input_price"
            )
        with col2:
            output_price = st.number_input(
                "è¾“å‡ºä»·æ ¼ (Â¥/1K tokens)",
                value=pricing_config.get("output_price", 0.004),
                min_value=0.0,
                max_value=1.0,
                step=0.0001,
                format="%.4f",
                key="token_output_price"
            )
        
        # ä¿å­˜æŒ‰é’®
        if st.form_submit_button("ğŸ’¾ ä¿å­˜ä»·æ ¼é…ç½®", type="primary"):
            new_pricing = {
                "input_price": input_price,
                "output_price": output_price
            }
            
            if save_token_pricing_config(new_pricing):
                st.success("âœ… Tokenä»·æ ¼å·²ä¿å­˜")
                st.rerun()
            else:
                st.error("âŒ ä¿å­˜å¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™")


def load_token_pricing_config():
    """åŠ è½½Tokenä»·æ ¼é…ç½®"""
    config_file = Path("config/pricing_config.json")
    
    if config_file.exists():
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # å¦‚æœæ˜¯æ—§æ ¼å¼ï¼Œè¿”å›é€šç”¨é…ç½®
                if isinstance(data, dict):
                    # ä¼˜å…ˆä½¿ç”¨openaié…ç½®ï¼Œç„¶ådashscopeï¼Œæœ€åç”¨é»˜è®¤å€¼
                    for provider in ['openai', 'dashscope', 'deepseek']:
                        if provider in data:
                            return data[provider]
                    # å¦‚æœæ˜¯æ–°çš„ç®€åŒ–æ ¼å¼
                    if 'input_price' in data and 'output_price' in data:
                        return data
        except Exception as e:
            st.warning(f"âš ï¸ åŠ è½½ä»·æ ¼é…ç½®å¤±è´¥: {e}")
    
    # è¿”å›é»˜è®¤é…ç½®
    return {"input_price": 0.002, "output_price": 0.004}


def save_token_pricing_config(pricing_config):
    """ä¿å­˜Tokenä»·æ ¼é…ç½®"""
    config_file = Path("config/pricing_config.json")
    
    try:
        # ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨
        config_file.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜ç®€åŒ–çš„ä»·æ ¼é…ç½®ï¼ŒåŒæ—¶ä¸ºæ‰€æœ‰providerè®¾ç½®ç›¸åŒä»·æ ¼
        unified_config = {
            "input_price": pricing_config["input_price"],
            "output_price": pricing_config["output_price"],
            # ä¸ºå…¼å®¹æ€§ä¿ç•™å„provideré…ç½®
            "deepseek": pricing_config,
            "dashscope": pricing_config,
            "openai": pricing_config,
            "google": pricing_config
        }
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(unified_config, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        st.error(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}")
        return False
