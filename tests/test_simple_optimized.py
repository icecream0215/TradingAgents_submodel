#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•æµ‹è¯•ä¼˜åŒ–é€‚é…å™¨ - éªŒè¯500é”™è¯¯è§£å†³æ–¹æ¡ˆ
"""

import os
import sys
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from tradingagents.llm_adapters.optimized_openai import OptimizedOpenAI, create_optimized_llm
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv

load_dotenv()

def test_optimized_solution():
    """æµ‹è¯•ä¼˜åŒ–è§£å†³æ–¹æ¡ˆ"""
    
    print("ğŸ¯ æµ‹è¯•ä¼˜åŒ–è§£å†³æ–¹æ¡ˆï¼šé¿å…500é”™è¯¯å’Œ'è¯•é”™'æœºåˆ¶")
    print("=" * 60)
    
    try:
        # 1. æµ‹è¯•ä¾¿æ·åˆ›å»ºå‡½æ•°
        print("1ï¸âƒ£ ä½¿ç”¨ä¾¿æ·å‡½æ•°åˆ›å»ºä¼˜åŒ–LLM...")
        
        llm = create_optimized_llm(
            streaming=False,  # éæµå¼ï¼Œæ›´ç¨³å®š
            temperature=0.7,
            max_tokens=100
        )
        
        print("âœ… ä¼˜åŒ–LLMåˆ›å»ºæˆåŠŸ")
        
        # 2. æµ‹è¯•å®é™…è°ƒç”¨
        print("\n2ï¸âƒ£ æµ‹è¯•å®é™…APIè°ƒç”¨...")
        
        test_query = "ç®€è¦åˆ†æä»Šæ—¥è‚¡å¸‚ï¼Œä¸è¶…è¿‡20å­—"
        messages = [HumanMessage(content=test_query)]
        
        print(f"ğŸ“ æŸ¥è¯¢: {test_query}")
        
        start_time = datetime.now()
        result = llm._generate(messages)
        end_time = datetime.now()
        
        duration = (end_time - start_time).total_seconds()
        
        if result and result.generations:
            response = result.generations[0].message.content
            print(f"âœ… APIè°ƒç”¨æˆåŠŸ ({duration:.2f}ç§’)")
            print(f"ğŸ“„ å“åº”: {response}")
            print("\nğŸ‰ ä¼˜åŒ–æˆåŠŸ:")
            print("   ğŸš€ æ— 500é”™è¯¯")
            print("   âš¡ æ— 'è¯•é”™'å»¶è¿Ÿ") 
            print("   ğŸ“Š ä¿æŒtokenç»Ÿè®¡")
            print(f"   â±ï¸ å¿«é€Ÿå“åº” ({duration:.2f}ç§’)")
            
            return True
        else:
            print("âŒ å“åº”ä¸ºç©º")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def show_usage_example():
    """æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹"""
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹ - å¦‚ä½•åœ¨ä½ çš„é¡¹ç›®ä¸­åº”ç”¨:")
    print("=" * 60)
    
    usage_code = '''
# 1. æ›¿æ¢ç°æœ‰çš„ThirdPartyOpenAI
from tradingagents.llm_adapters.optimized_openai import create_optimized_llm

# 2. åˆ›å»ºä¼˜åŒ–çš„LLMå®ä¾‹ï¼ˆæ¨èéæµå¼ï¼‰
llm = create_optimized_llm(
    streaming=False,      # å…³é”®ï¼šé¿å…500é”™è¯¯
    temperature=0.7,
    max_tokens=2000
)

# 3. æ­£å¸¸ä½¿ç”¨ï¼ˆæ— éœ€æ‹…å¿ƒ500é”™è¯¯ï¼‰
from langchain_core.messages import HumanMessage

messages = [HumanMessage(content="åˆ†æè‚¡å¸‚è¶‹åŠ¿")]
result = llm._generate(messages)

if result and result.generations:
    response = result.generations[0].message.content
    print(f"å“åº”: {response}")
    '''
    
    print(usage_code)
    
    print("ğŸ’¡ æ ¸å¿ƒæ”¹è¿›:")
    print("   1. ç›´æ¥ä½¿ç”¨æœ€ä½³å®ç°ï¼Œè·³è¿‡LangChainçš„'è¯•é”™'æœºåˆ¶")
    print("   2. é»˜è®¤éæµå¼æ¨¡å¼ï¼Œé¿å…500è¶…æ—¶é”™è¯¯") 
    print("   3. ä¿æŒæ‰€æœ‰ç°æœ‰åŠŸèƒ½ï¼štokenç»Ÿè®¡ã€ä¼šè¯ç®¡ç†ç­‰")
    print("   4. å‘åå…¼å®¹ï¼šå¯ç›´æ¥æ›¿æ¢ThirdPartyOpenAI")

if __name__ == "__main__":
    
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        sys.exit(1)
    
    # è¿è¡Œæµ‹è¯•
    success = test_optimized_solution()
    
    # æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
    show_usage_example()
    
    if success:
        print(f"\nğŸ‰ ä¼˜åŒ–æ–¹æ¡ˆéªŒè¯æˆåŠŸ!")
        print("ğŸ”§ ç°åœ¨ä½ å¯ä»¥:")
        print("   1. ä½¿ç”¨ OptimizedOpenAI æ›¿æ¢ ThirdPartyOpenAI")
        print("   2. äº«å—æ— 500é”™è¯¯çš„ç¨³å®šä½“éªŒ")
        print("   3. èŠ‚çœ'è¯•é”™'æœºåˆ¶æµªè´¹çš„æ—¶é—´")
    else:
        print("\nâŒ æµ‹è¯•æœªé€šè¿‡ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")