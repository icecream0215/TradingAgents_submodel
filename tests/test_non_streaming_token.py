#!/usr/bin/env python3
"""
æµ‹è¯•éæµå¼å“åº”çš„Tokenä½¿ç”¨ç»Ÿè®¡
éªŒè¯èƒ½å¦è·å–çœŸå®çš„tokenç”¨é‡æ•°æ®
"""

import os
import sys
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from tradingagents.llm_adapters.third_party_openai import ThirdPartyOpenAI
from tradingagents.config.config_manager import config_manager, token_tracker
from tradingagents.utils.logging_manager import get_logger
from langchain_core.messages import HumanMessage, SystemMessage

logger = get_logger('test')

def load_env_config():
    """åŠ è½½ç¯å¢ƒé…ç½®"""
    from dotenv import load_dotenv
    env_file = Path(__file__).parent / ".env"
    if env_file.exists():
        load_dotenv(env_file, override=True)
        logger.info("âœ… ç¯å¢ƒé…ç½®åŠ è½½æˆåŠŸ")
    else:
        logger.warning("âš ï¸ .envæ–‡ä»¶æœªæ‰¾åˆ°")

def test_non_streaming_token_tracking():
    """æµ‹è¯•éæµå¼å“åº”çš„Tokenè·Ÿè¸ªåŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•éæµå¼å“åº”Tokenè·Ÿè¸ªåŠŸèƒ½...")
    
    # è·å–APIé…ç½®
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = "https://llm.submodel.ai/v1"
    
    if not api_key:
        logger.error("âŒ æœªé…ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        return False
    
    try:
        # åˆ›å»ºThirdPartyOpenAIé€‚é…å™¨ï¼ˆéæµå¼ï¼‰
        logger.info(f"ğŸš€ åˆå§‹åŒ–éæµå¼ThirdPartyOpenAIé€‚é…å™¨...")
        
        llm = ThirdPartyOpenAI(
            model="Qwen/Qwen3-235B-A22B-Instruct-2507",
            api_key=api_key,
            base_url=base_url,
            temperature=0.7,
            max_tokens=200,
            streaming=False,  # å…³é—­æµå¼å“åº”
            stream=False     # ç¡®ä¿éæµå¼
        )
        
        # ç”Ÿæˆå”¯ä¸€ä¼šè¯ID
        session_id = f"non_stream_test_{int(time.time())}"
        logger.info(f"ğŸ“ ä¼šè¯ID: {session_id}")
        
        # æµ‹è¯•æ¶ˆæ¯
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆã€‚"),
            HumanMessage(content="ç®€å•åˆ†æä¸€ä¸‹è…¾è®¯è‚¡ç¥¨ï¼Œä¸è¶…è¿‡30å­—ã€‚")
        ]
        
        logger.info(f"ğŸš€ å‘é€éæµå¼è¯·æ±‚...")
        
        # è®°å½•æµ‹è¯•å‰çš„ä½¿ç”¨è®°å½•æ•°é‡
        initial_records = config_manager.load_usage_records()
        initial_count = len(initial_records)
        logger.info(f"ğŸ“Š æµ‹è¯•å‰è®°å½•æ•°: {initial_count}")
        
        # è°ƒç”¨LLMï¼ˆéæµå¼ï¼‰
        response = llm.invoke(
            messages,
            session_id=session_id,
            analysis_type="non_stream_test"
        )
        
        logger.info(f"âœ… æ”¶åˆ°éæµå¼å“åº”:")
        logger.info(f"   {response.content[:100]}{'...' if len(response.content) > 100 else ''}")
        
        # ç­‰å¾…è®°å½•ä¿å­˜
        time.sleep(2)
        
        # æŸ¥çœ‹ä¼šè¯æˆæœ¬
        session_cost = token_tracker.get_session_cost(session_id)
        logger.info(f"ğŸ’° æœ¬æ¬¡åˆ†ææˆæœ¬: Â¥{session_cost:.6f}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„tokenä½¿ç”¨è®°å½•
        final_records = config_manager.load_usage_records()
        final_count = len(final_records)
        logger.info(f"ğŸ“Š æµ‹è¯•åè®°å½•æ•°: {final_count}")
        
        if final_count > initial_count:
            # è·å–æ–°å¢çš„è®°å½•
            new_records = final_records[initial_count:]
            for i, record in enumerate(new_records):
                logger.info(f"ğŸ“Š æ–°å¢è®°å½• #{i+1}:")
                logger.info(f"   ä¾›åº”å•†: {record.provider}")
                logger.info(f"   æ¨¡å‹: {record.model_name}")
                logger.info(f"   è¾“å…¥tokens: {record.input_tokens}")
                logger.info(f"   è¾“å‡ºtokens: {record.output_tokens}")
                logger.info(f"   æˆæœ¬: Â¥{record.cost:.6f}")
                logger.info(f"   ä¼šè¯ID: {record.session_id}")
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºçœŸå®æ•°æ®ï¼ˆéä¼°ç®—ï¼‰
                if record.input_tokens > 0 and record.output_tokens > 0:
                    # éæµå¼å“åº”åº”è¯¥èƒ½è·å–åˆ°æ›´å‡†ç¡®çš„tokenæ•°æ®
                    if record.input_tokens < 1000 and record.output_tokens < 1000:  # åˆç†èŒƒå›´
                        logger.info(f"âœ… è·å–åˆ°äº†åˆç†çš„Tokenç”¨é‡æ•°æ®")
                        return True
                    else:
                        logger.warning(f"âš ï¸ Tokenç”¨é‡æ•°æ®å¯èƒ½ä¸å‡†ç¡®")
                        return True  # ä¾ç„¶ç®—æˆåŠŸï¼Œå› ä¸ºæœ‰æ•°æ®
                else:
                    logger.warning(f"âš ï¸ Tokenç”¨é‡æ•°æ®ä¸º0")
                    return False
        else:
            logger.error(f"âŒ æœªæ‰¾åˆ°æ–°å¢çš„ä¼šè¯è®°å½•")
            return False
            
    except Exception as e:
        logger.error(f"âŒ éæµå¼Tokenè·Ÿè¸ªæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False

def display_current_statistics():
    """æ˜¾ç¤ºå½“å‰ç»Ÿè®¡ä¿¡æ¯"""
    logger.info("ğŸ“Š æ˜¾ç¤ºå½“å‰ç»Ÿè®¡ä¿¡æ¯...")
    
    try:
        # è·å–æœ€è¿‘7å¤©çš„ç»Ÿè®¡
        stats = config_manager.get_usage_statistics(7)
        logger.info(f"ğŸ“Š æœ€è¿‘7å¤©ç»Ÿè®¡:")
        logger.info(f"   ğŸ’° æ€»æˆæœ¬: Â¥{stats['total_cost']:.6f}")
        logger.info(f"   ğŸ“ æ€»è¯·æ±‚: {stats['total_requests']}")
        logger.info(f"   ğŸ“¥ è¾“å…¥tokens: {stats['total_input_tokens']:,}")
        logger.info(f"   ğŸ“¤ è¾“å‡ºtokens: {stats['total_output_tokens']:,}")
        
        # æ˜¾ç¤ºä¾›åº”å•†ç»Ÿè®¡
        provider_stats = stats.get('provider_stats', {})
        if provider_stats:
            logger.info(f"   ğŸ“ˆ ä¾›åº”å•†ç»Ÿè®¡:")
            for provider, pstats in provider_stats.items():
                logger.info(f"      {provider}: Â¥{pstats['cost']:.6f} ({pstats['requests']}æ¬¡è¯·æ±‚)")
        
        return True
    except Exception as e:
        logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸ¯ éæµå¼Tokenè·Ÿè¸ªæµ‹è¯•")
    logger.info("=" * 50)
    
    # 1. åŠ è½½ç¯å¢ƒé…ç½®
    load_env_config()
    
    # 2. æ˜¾ç¤ºå½“å‰ç»Ÿè®¡
    display_current_statistics()
    
    # 3. æµ‹è¯•éæµå¼Tokenè·Ÿè¸ª
    test_result = test_non_streaming_token_tracking()
    
    # 4. æ˜¾ç¤ºæ›´æ–°åçš„ç»Ÿè®¡
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“ˆ æµ‹è¯•åç»Ÿè®¡ä¿¡æ¯:")
    display_current_statistics()
    
    # 5. æ€»ç»“
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
    
    if test_result:
        logger.info("ğŸ‰ éæµå¼Tokenä½¿ç”¨é‡æµ‹è¯•æˆåŠŸï¼")
        logger.info("âœ… ç³»ç»Ÿèƒ½å¤Ÿè·å–å’Œè®°å½•Tokenç”¨é‡æ•°æ®")
    else:
        logger.error("âŒ éæµå¼Tokenä½¿ç”¨é‡æµ‹è¯•å¤±è´¥")
    
    logger.info("\nğŸ“š ç›¸å…³æ–‡ä»¶:")
    logger.info("   - é…ç½®: .env")
    logger.info("   - è®°å½•: config/usage.json")
    logger.info("   - ä»£ç : tradingagents/llm_adapters/third_party_openai.py")

if __name__ == "__main__":
    main()