#!/usr/bin/env python3
"""
æµ‹è¯•æµå¼å“åº”ä¸­æ˜¯å¦åŒ…å«usageä¿¡æ¯
æ£€æŸ¥ç¬¬ä¸‰æ–¹APIåœ¨æµå¼å“åº”ç»“æŸæ—¶æ˜¯å¦æä¾›tokenä½¿ç”¨ç»Ÿè®¡
"""

import os
import sys
import json
import requests
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from tradingagents.utils.logging_manager import get_logger

logger = get_logger('stream_test')

def load_env_config():
    """åŠ è½½ç¯å¢ƒé…ç½®"""
    from dotenv import load_dotenv
    env_file = Path(__file__).parent / ".env"
    if env_file.exists():
        load_dotenv(env_file, override=True)
        logger.info("âœ… ç¯å¢ƒé…ç½®åŠ è½½æˆåŠŸ")
    else:
        logger.warning("âš ï¸ .envæ–‡ä»¶æœªæ‰¾åˆ°")

def test_streaming_response_usage():
    """æµ‹è¯•æµå¼å“åº”æ˜¯å¦åŒ…å«usageä¿¡æ¯"""
    logger.info("ğŸ” æµ‹è¯•æµå¼å“åº”ä¸­çš„usageä¿¡æ¯...")
    
    # è·å–APIé…ç½®
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = "https://llm.submodel.ai/v1"
    
    if not api_key:
        logger.error("âŒ æœªé…ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        return False
    
    try:
        # æ„å»ºè¯·æ±‚æ•°æ®
        request_data = {
            'model': 'Qwen/Qwen3-235B-A22B-Instruct-2507',
            'messages': [
                {'role': 'user', 'content': 'è¯·è¯´ä½ å¥½'}
            ],
            'temperature': 0.7,
            'max_tokens': 50,
            'stream': True  # æµå¼è¯·æ±‚
        }
        
        # è¯·æ±‚å¤´
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}'
        }
        
        api_url = f"{base_url}/chat/completions"
        logger.info(f"ğŸŒ æµå¼APIè°ƒç”¨: {api_url}")
        logger.info(f"ğŸ“ è¯·æ±‚æ•°æ®: {request_data}")
        
        response = requests.post(
            api_url,
            headers=headers,
            json=request_data,
            timeout=120,
            stream=True
        )
        
        logger.info(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code != 200:
            logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
            return False
        
        # å¤„ç†æµå¼å“åº”
        full_content = ""
        chunk_count = 0
        usage_found = False
        final_usage = None
        
        logger.info("ğŸ“Š å¼€å§‹è§£ææµå¼å“åº”chunks:")
        logger.info("-" * 60)
        
        for line in response.iter_lines():
            if line:
                decoded_line = line.decode('utf-8')
                if decoded_line.startswith('data: '):
                    data_str = decoded_line[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
                    
                    logger.info(f"Chunk {chunk_count}: {data_str}")
                    
                    if data_str == '[DONE]':
                        logger.info("âœ… æ”¶åˆ°[DONE]æ ‡è®°ï¼Œæµå¼å“åº”ç»“æŸ")
                        break
                    
                    try:
                        chunk_data = json.loads(data_str)
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰choiceså­—æ®µï¼ˆæ­£å¸¸å†…å®¹ï¼‰
                        if 'choices' in chunk_data and len(chunk_data['choices']) > 0:
                            delta = chunk_data['choices'][0].get('delta', {})
                            content = delta.get('content', '')
                            if content:
                                full_content += content
                                logger.info(f"  å†…å®¹: {repr(content)}")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰usageå­—æ®µ
                        if 'usage' in chunk_data:
                            usage_found = True
                            final_usage = chunk_data['usage']
                            logger.info(f"ğŸ¯ æ‰¾åˆ°usageä¿¡æ¯: {final_usage}")
                        
                        # æ˜¾ç¤ºå®Œæ•´çš„chunkç»“æ„ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰
                        logger.debug(f"  å®Œæ•´chunk: {json.dumps(chunk_data, indent=2, ensure_ascii=False)}")
                        
                        chunk_count += 1
                        
                    except json.JSONDecodeError as e:
                        logger.warning(f"âš ï¸ æ— æ³•è§£ææµå¼æ•°æ®: {data_str} - é”™è¯¯: {e}")
        
        logger.info("-" * 60)
        logger.info(f"ğŸ“Š æµå¼å“åº”åˆ†æç»“æœ:")
        logger.info(f"  æ€»chunksæ•°: {chunk_count}")
        logger.info(f"  å®Œæ•´å†…å®¹: {repr(full_content)}")
        logger.info(f"  å†…å®¹é•¿åº¦: {len(full_content)}å­—ç¬¦")
        logger.info(f"  åŒ…å«usage: {'âœ…' if usage_found else 'âŒ'}")
        
        if usage_found:
            logger.info(f"ğŸ¯ Usageä¿¡æ¯è¯¦æƒ…:")
            logger.info(f"  prompt_tokens: {final_usage.get('prompt_tokens', 'N/A')}")
            logger.info(f"  completion_tokens: {final_usage.get('completion_tokens', 'N/A')}")
            logger.info(f"  total_tokens: {final_usage.get('total_tokens', 'N/A')}")
            return final_usage
        else:
            logger.warning(f"âš ï¸ æµå¼å“åº”ä¸­æœªæ‰¾åˆ°usageä¿¡æ¯")
            # æ‰‹åŠ¨ä¼°ç®—è¿›è¡Œå¯¹æ¯”
            input_text = 'è¯·è¯´ä½ å¥½'
            estimated_input = max(1, int(len(input_text) * 0.75))
            estimated_output = max(1, int(len(full_content) * 0.75))
            logger.info(f"ğŸ“Š ä¼°ç®—å¯¹æ¯”:")
            logger.info(f"  ä¼°ç®—è¾“å…¥tokens: {estimated_input}")
            logger.info(f"  ä¼°ç®—è¾“å‡ºtokens: {estimated_output}")
            return None
            
    except Exception as e:
        logger.error(f"âŒ æµå¼å“åº”æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return None

def test_non_streaming_response_usage():
    """æµ‹è¯•éæµå¼å“åº”çš„usageä¿¡æ¯ä½œä¸ºå¯¹æ¯”"""
    logger.info("ğŸ” æµ‹è¯•éæµå¼å“åº”ä¸­çš„usageä¿¡æ¯ï¼ˆå¯¹æ¯”ï¼‰...")
    
    # è·å–APIé…ç½®
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = "https://llm.submodel.ai/v1"
    
    try:
        # æ„å»ºè¯·æ±‚æ•°æ®ï¼ˆéæµå¼ï¼‰
        request_data = {
            'model': 'Qwen/Qwen3-235B-A22B-Instruct-2507',
            'messages': [
                {'role': 'user', 'content': 'è¯·è¯´ä½ å¥½'}
            ],
            'temperature': 0.7,
            'max_tokens': 50,
            'stream': False  # éæµå¼è¯·æ±‚
        }
        
        # è¯·æ±‚å¤´
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}'
        }
        
        api_url = f"{base_url}/chat/completions"
        
        response = requests.post(
            api_url,
            headers=headers,
            json=request_data,
            timeout=120
        )
        
        logger.info(f"ğŸ“¡ éæµå¼å“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            logger.info(f"ğŸ“Š éæµå¼å“åº”ç»“æ„:")
            logger.info(f"{json.dumps(data, indent=2, ensure_ascii=False)}")
            
            if 'usage' in data:
                usage = data['usage']
                logger.info(f"âœ… éæµå¼å“åº”åŒ…å«usage: {usage}")
                return usage
            else:
                logger.warning(f"âš ï¸ éæµå¼å“åº”ä¹Ÿæ²¡æœ‰usageä¿¡æ¯")
                return None
        else:
            logger.error(f"âŒ éæµå¼APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
            return None
            
    except Exception as e:
        logger.error(f"âŒ éæµå¼å“åº”æµ‹è¯•å¤±è´¥: {e}")
        return None

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸ¯ æµå¼å“åº”Usageä¿¡æ¯æµ‹è¯•")
    logger.info("=" * 80)
    
    # 1. åŠ è½½ç¯å¢ƒé…ç½®
    load_env_config()
    
    # 2. æµ‹è¯•æµå¼å“åº”
    streaming_usage = test_streaming_response_usage()
    
    logger.info("\n" + "=" * 80)
    
    # 3. æµ‹è¯•éæµå¼å“åº”ï¼ˆå¯¹æ¯”ï¼‰
    non_streaming_usage = test_non_streaming_response_usage()
    
    # 4. æ€»ç»“
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
    
    if streaming_usage:
        logger.info("ğŸ‰ æµå¼å“åº”åŒ…å«å‡†ç¡®çš„usageä¿¡æ¯ï¼")
        logger.info("ğŸ’¡ å¯ä»¥ä¿®æ”¹é€‚é…å™¨æ¥è§£ææµå¼å“åº”ä¸­çš„usageæ•°æ®")
    elif non_streaming_usage:
        logger.info("âš ï¸ åªæœ‰éæµå¼å“åº”åŒ…å«usageä¿¡æ¯")
        logger.info("ğŸ’¡ å»ºè®®ï¼š")
        logger.info("   1. ä¼˜å…ˆä½¿ç”¨éæµå¼å“åº”è·å–å‡†ç¡®tokenæ•°æ®")
        logger.info("   2. æˆ–è€…åœ¨æµå¼å“åº”åå‘é€ä¸€ä¸ªç®€å•çš„éæµå¼è¯·æ±‚è·å–usage")
    else:
        logger.warning("âŒ ä¸¤ç§å“åº”éƒ½æ²¡æœ‰usageä¿¡æ¯")
        logger.info("ğŸ’¡ åªèƒ½ä¾èµ–ä¼°ç®—æ–¹æ³•")
    
    logger.info("\nğŸ“š å¦‚æœæµå¼å“åº”åŒ…å«usageä¿¡æ¯ï¼Œå¯ä»¥ä¿®æ”¹:")
    logger.info("   - tradingagents/llm_adapters/third_party_openai.py")
    logger.info("   - åœ¨æµå¼å“åº”å¤„ç†ä¸­æ£€æŸ¥å¹¶æå–usageå­—æ®µ")

if __name__ == "__main__":
    main()