#!/usr/bin/env python3
"""
Submodel LLMæœåŠ¡Tokenä½¿ç”¨é‡æµ‹è¯•è„šæœ¬
æµ‹è¯•åœ¨ä½¿ç”¨submodelæä¾›çš„LLMæœåŠ¡æ—¶tokenç”¨é‡æ•°æ®èƒ½å¦æ­£ç¡®è·å–
"""

import os
import sys
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from tradingagents.llm_adapters.openai_compatible_base import ChatCustomOpenAI, create_openai_compatible_llm
from tradingagents.config.config_manager import config_manager, token_tracker
from tradingagents.utils.logging_manager import get_logger
from langchain_core.messages import HumanMessage, SystemMessage

logger = get_logger('default')

def load_env_config():
    """åŠ è½½ç¯å¢ƒé…ç½®"""
    from dotenv import load_dotenv
    env_file = Path(__file__).parent / ".env"
    if env_file.exists():
        load_dotenv(env_file, override=True)
        logger.info("âœ… ç¯å¢ƒé…ç½®åŠ è½½æˆåŠŸ")
    else:
        logger.warning("âš ï¸ .envæ–‡ä»¶æœªæ‰¾åˆ°")

def test_submodel_openai_endpoint():
    """æµ‹è¯•submodel OpenAIç«¯ç‚¹çš„tokenç”¨é‡è·å–"""
    logger.info("ğŸ§ª æµ‹è¯•submodel OpenAIç«¯ç‚¹...")
    
    # è·å–APIé…ç½®
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = "https://llm.submodel.ai/v1"
    
    if not api_key:
        logger.error("âŒ æœªé…ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        return False
    
    try:
        # åˆ›å»ºè‡ªå®šä¹‰OpenAIé€‚é…å™¨
        logger.info(f"ğŸš€ åˆå§‹åŒ–submodel OpenAIé€‚é…å™¨...")
        logger.info(f"   API Base: {base_url}")
        
        llm = ChatCustomOpenAI(
            model="Qwen/Qwen3-235B-A22B-Instruct-2507",  # ä½¿ç”¨ç”¨æˆ·å®é™…ä½¿ç”¨çš„æ¨¡å‹
            api_key=api_key,
            base_url=base_url,
            temperature=0.7,
            max_tokens=200
        )
        
        # ç”Ÿæˆå”¯ä¸€ä¼šè¯ID
        session_id = f"submodel_test_{int(time.time())}"
        logger.info(f"ğŸ“ ä¼šè¯ID: {session_id}")
        
        # æµ‹è¯•æ¶ˆæ¯
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆï¼Œè¯·æä¾›ç®€æ´å‡†ç¡®çš„åˆ†æã€‚"),
            HumanMessage(content="è¯·ç®€å•åˆ†æä¸€ä¸‹å½“å‰Aè‚¡å¸‚åœºçš„æ•´ä½“è¶‹åŠ¿ï¼Œä¸è¶…è¿‡50å­—ã€‚")
        ]
        
        logger.info(f"ğŸš€ å‘é€æµ‹è¯•è¯·æ±‚...")
        
        # è®°å½•æµ‹è¯•å‰çš„ä½¿ç”¨è®°å½•æ•°é‡
        initial_records = config_manager.load_usage_records()
        initial_count = len(initial_records)
        logger.info(f"ğŸ“Š æµ‹è¯•å‰è®°å½•æ•°: {initial_count}")
        
        # è°ƒç”¨LLMï¼ˆè‡ªåŠ¨è®°å½•tokenä½¿ç”¨ï¼‰
        response = llm.invoke(
            messages,
            session_id=session_id,
            analysis_type="market_analysis"
        )
        
        logger.info(f"âœ… æ”¶åˆ°å“åº”:")
        logger.info(f"   {response.content[:100]}{'...' if len(response.content) > 100 else ''}")
        
        # ç­‰å¾…è®°å½•ä¿å­˜
        time.sleep(2)
        
        # æŸ¥çœ‹ä¼šè¯æˆæœ¬
        session_cost = token_tracker.get_session_cost(session_id)
        logger.info(f"ğŸ’° æœ¬æ¬¡åˆ†ææˆæœ¬: Â¥{session_cost:.6f}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„tokenä½¿ç”¨è®°å½•
        final_records = config_manager.load_usage_records()
        final_count = len(final_records)
        logger.info(f"ğŸ“Š æµ‹è¯•åè®°å½•æ•°: {final_count}")
        
        if final_count > initial_count:
            # è·å–æ–°å¢çš„è®°å½•
            new_records = final_records[initial_count:]
            for i, record in enumerate(new_records):
                logger.info(f"ğŸ“Š æ–°å¢è®°å½• #{i+1}:")
                logger.info(f"   ä¾›åº”å•†: {record.provider}")
                logger.info(f"   æ¨¡å‹: {record.model_name}")
                logger.info(f"   è¾“å…¥tokens: {record.input_tokens}")
                logger.info(f"   è¾“å‡ºtokens: {record.output_tokens}")
                logger.info(f"   æˆæœ¬: Â¥{record.cost:.6f}")
                logger.info(f"   ä¼šè¯ID: {record.session_id}")
                
                # éªŒè¯æ•°æ®æ˜¯å¦çœŸå®
                if record.input_tokens > 0 and record.output_tokens > 0:
                    logger.info(f"âœ… Tokenç”¨é‡æ•°æ®è·å–æˆåŠŸä¸”çœŸå®")
                    return True
                else:
                    logger.warning(f"âš ï¸ Tokenç”¨é‡æ•°æ®ä¸º0ï¼Œå¯èƒ½ä¸æ˜¯çœŸå®æ•°æ®")
                    return False
        else:
            logger.error(f"âŒ æœªæ‰¾åˆ°æ–°å¢çš„ä¼šè¯è®°å½•")
            return False
            
    except Exception as e:
        logger.error(f"âŒ submodel OpenAIæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False

def test_create_openai_compatible_llm():
    """æµ‹è¯•create_openai_compatible_llmå·¥å‚å‡½æ•°"""
    logger.info("ğŸ”§ æµ‹è¯•create_openai_compatible_llmå·¥å‚å‡½æ•°...")
    
    try:
        # è·å–APIé…ç½®
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            logger.error("âŒ æœªé…ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
            return False
        
        # ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»ºè‡ªå®šä¹‰OpenAIé€‚é…å™¨
        llm = create_openai_compatible_llm(
            provider="custom_openai",
            model="Qwen/Qwen3-235B-A22B-Instruct-2507",
            api_key=api_key,
            base_url="https://llm.submodel.ai/v1",
            temperature=0.7,
            max_tokens=100
        )
        
        logger.info(f"âœ… å·¥å‚å‡½æ•°åˆ›å»ºé€‚é…å™¨æˆåŠŸ")
        logger.info(f"   ä¾›åº”å•†: {llm.provider_name}")
        logger.info(f"   æ¨¡å‹: {llm.model_name}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ å·¥å‚å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        return False

def display_current_statistics():
    """æ˜¾ç¤ºå½“å‰ç»Ÿè®¡ä¿¡æ¯"""
    logger.info("ğŸ“Š æ˜¾ç¤ºå½“å‰ç»Ÿè®¡ä¿¡æ¯...")
    
    try:
        # è·å–æœ€è¿‘7å¤©çš„ç»Ÿè®¡
        stats = config_manager.get_usage_statistics(7)
        logger.info(f"ğŸ“Š æœ€è¿‘7å¤©ç»Ÿè®¡:")
        logger.info(f"   ğŸ’° æ€»æˆæœ¬: Â¥{stats['total_cost']:.6f}")
        logger.info(f"   ğŸ“ æ€»è¯·æ±‚: {stats['total_requests']}")
        logger.info(f"   ğŸ“¥ è¾“å…¥tokens: {stats['total_input_tokens']:,}")
        logger.info(f"   ğŸ“¤ è¾“å‡ºtokens: {stats['total_output_tokens']:,}")
        
        # æ˜¾ç¤ºä¾›åº”å•†ç»Ÿè®¡
        provider_stats = stats.get('provider_stats', {})
        if provider_stats:
            logger.info(f"   ğŸ“ˆ ä¾›åº”å•†ç»Ÿè®¡:")
            for provider, pstats in provider_stats.items():
                logger.info(f"      {provider}: Â¥{pstats['cost']:.6f} ({pstats['requests']}æ¬¡è¯·æ±‚)")
        
        return True
    except Exception as e:
        logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return False

def check_token_tracking_status():
    """æ£€æŸ¥tokenè·Ÿè¸ªçŠ¶æ€"""
    logger.info("ğŸ” æ£€æŸ¥tokenè·Ÿè¸ªçŠ¶æ€...")
    
    # æ£€æŸ¥é…ç½®ç®¡ç†å™¨
    logger.info(f"ğŸ”§ é…ç½®ç®¡ç†å™¨çŠ¶æ€:")
    logger.info(f"   é…ç½®ç›®å½•: {config_manager.config_dir}")
    logger.info(f"   ä½¿ç”¨è®°å½•æ–‡ä»¶: {config_manager.usage_file.exists()}")
    logger.info(f"   å®šä»·é…ç½®æ–‡ä»¶: {config_manager.pricing_file.exists()}")
    
    # æ£€æŸ¥tokenè·Ÿè¸ªå™¨
    logger.info(f"ğŸ“Š Tokenè·Ÿè¸ªå™¨çŠ¶æ€:")
    logger.info(f"   å¯ç”¨çŠ¶æ€: True")
    
    # æ£€æŸ¥å®šä»·é…ç½®
    try:
        from web.components.pricing_config import load_pricing_config
        pricing_config = load_pricing_config()
        logger.info(f"ğŸ’° å®šä»·é…ç½®:")
        for provider, prices in pricing_config.items():
            if isinstance(prices, dict) and "input_price" in prices:
                logger.info(f"   {provider}: è¾“å…¥Â¥{prices['input_price']}/1K, è¾“å‡ºÂ¥{prices['output_price']}/1K")
            else:
                logger.info(f"   {provider}: {prices}")
    except Exception as e:
        logger.error(f"âŒ å®šä»·é…ç½®æ£€æŸ¥å¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸ¯ Submodel LLMæœåŠ¡Tokenä½¿ç”¨é‡æµ‹è¯•")
    logger.info("=" * 50)
    
    # 1. åŠ è½½ç¯å¢ƒé…ç½®
    load_env_config()
    
    # 2. æ£€æŸ¥tokenè·Ÿè¸ªçŠ¶æ€
    check_token_tracking_status()
    
    # 3. æ˜¾ç¤ºå½“å‰ç»Ÿè®¡
    display_current_statistics()
    
    # 4. æµ‹è¯•å·¥å‚å‡½æ•°
    factory_test_result = test_create_openai_compatible_llm()
    
    # 5. æµ‹è¯•submodel OpenAIç«¯ç‚¹
    api_test_result = test_submodel_openai_endpoint()
    
    # 6. æ˜¾ç¤ºæ›´æ–°åçš„ç»Ÿè®¡
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“ˆ æµ‹è¯•åç»Ÿè®¡ä¿¡æ¯:")
    display_current_statistics()
    
    # 7. æ€»ç»“
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
    
    if factory_test_result:
        logger.info("âœ… å·¥å‚å‡½æ•°æµ‹è¯•æˆåŠŸ")
    else:
        logger.error("âŒ å·¥å‚å‡½æ•°æµ‹è¯•å¤±è´¥")
    
    if api_test_result:
        logger.info("ğŸ‰ Submodel LLMæœåŠ¡Tokenä½¿ç”¨é‡æµ‹è¯•æˆåŠŸï¼")
        logger.info("âœ… ç³»ç»Ÿèƒ½å¤Ÿæ­£ç¡®è·å–å’Œè®°å½•submodel LLMæœåŠ¡çš„tokenç”¨é‡æ•°æ®")
    else:
        logger.error("âŒ Submodel LLMæœåŠ¡Tokenä½¿ç”¨é‡æµ‹è¯•å¤±è´¥")
        logger.info("ğŸ’¡ å¯èƒ½çš„åŸå› :")
        logger.info("   1. APIå¯†é’¥é…ç½®ä¸æ­£ç¡®")
        logger.info("   2. ç½‘ç»œè¿æ¥é—®é¢˜")
        logger.info("   3. submodelæœåŠ¡ç«¯æœªè¿”å›tokenç”¨é‡ä¿¡æ¯")
        logger.info("   4. Tokenè·Ÿè¸ªåŠŸèƒ½é…ç½®é—®é¢˜")
    
    logger.info("\nğŸ“š ç›¸å…³æ–‡ä»¶:")
    logger.info("   - é…ç½®: .env")
    logger.info("   - è®°å½•: config/usage.json")
    logger.info("   - ä»£ç : tradingagents/llm_adapters/openai_compatible_base.py")

if __name__ == "__main__":
    main()
