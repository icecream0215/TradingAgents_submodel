#!/usr/bin/env python3
"""
å®‰å…¨APIè°ƒç”¨æµ‹è¯•è„šæœ¬
================

åŸºäº500é”™è¯¯åˆ†æç»“æœï¼Œåˆ›å»ºä¸€ä¸ªå®‰å…¨çš„APIè°ƒç”¨æµ‹è¯•ã€‚
è¿™ä¸ªè„šæœ¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä¸“ç”¨é€‚é…å™¨æ¥é¿å…å‚æ•°ä¸å…¼å®¹é—®é¢˜ã€‚
"""

import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

import logging
from langchain.schema import HumanMessage, SystemMessage
from tradingagents.llm_adapters import get_adapter_by_name, list_available_models

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("safe_api_test")

def test_safe_gpt_oss_call():
    """æµ‹è¯•å®‰å…¨çš„GPT-OSS APIè°ƒç”¨"""
    logger.info("ğŸ§ª æµ‹è¯•å®‰å…¨çš„GPT-OSS APIè°ƒç”¨")
    logger.info("=" * 40)
    
    try:
        # 1. è·å–é€‚é…å™¨
        adapter = get_adapter_by_name("gpt-oss")
        if not adapter:
            logger.error("âŒ æ— æ³•è·å–GPT-OSSé€‚é…å™¨")
            return False
        
        logger.info(f"âœ… é€‚é…å™¨è·å–æˆåŠŸ: {adapter.model_name}")
        
        # 2. æ„å»ºå®‰å…¨çš„æ¶ˆæ¯
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨æŠ€æœ¯åˆ†æå¸ˆã€‚è¯·åŸºäºæä¾›çš„è‚¡ç¥¨ä»£ç ç»™å‡ºç®€çŸ­çš„æŠ€æœ¯åˆ†æå»ºè®®ã€‚"),
            HumanMessage(content="è¯·åˆ†æè‚¡ç¥¨ä»£ç 600519çš„æŠ€æœ¯æŒ‡æ ‡ã€‚")
        ]
        
        logger.info("ğŸ“ æ¶ˆæ¯æ„å»ºå®Œæˆ:")
        for i, msg in enumerate(messages, 1):
            logger.info(f"   æ¶ˆæ¯{i}: {type(msg).__name__} - {msg.content[:50]}...")
        
        # 3. å®‰å…¨å‚æ•°è®¾ç½®
        safe_kwargs = {
            "temperature": 0.7,
            "max_tokens": 500,  # å‡å°‘tokenæ•°é‡é¿å…è¶…é™
            "top_p": 0.9,
            "frequency_penalty": 0.1,
            "presence_penalty": 0.1,
            "stop": ["END"]
        }
        
        logger.info("âš™ï¸ ä½¿ç”¨å®‰å…¨å‚æ•°:")
        for key, value in safe_kwargs.items():
            logger.info(f"   {key}: {value}")
        
        # 4. æ‰§è¡Œè°ƒç”¨ï¼ˆä½¿ç”¨é€‚é…å™¨çš„å‚æ•°è¿‡æ»¤åŠŸèƒ½ï¼‰
        logger.info("\nğŸš€ å¼€å§‹APIè°ƒç”¨...")
        
        # é€‚é…å™¨ä¼šè‡ªåŠ¨è¿‡æ»¤ä¸å…¼å®¹çš„å‚æ•°
        response = adapter.invoke(messages, **safe_kwargs)
        
        logger.info("âœ… APIè°ƒç”¨æˆåŠŸ!")
        logger.info(f"ğŸ“„ å“åº”å†…å®¹: {response.content[:200]}...")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        return False

def test_multiple_models_safely():
    """æµ‹è¯•å¤šä¸ªæ¨¡å‹çš„å®‰å…¨è°ƒç”¨"""
    logger.info("\nğŸ”„ æµ‹è¯•å¤šä¸ªæ¨¡å‹çš„å®‰å…¨è°ƒç”¨")
    logger.info("=" * 40)
    
    # è·å–å¯ç”¨æ¨¡å‹
    models = list_available_models()
    logger.info(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {models}")
    
    # æµ‹è¯•å‡ ä¸ªç¨³å®šçš„æ¨¡å‹
    test_models = ["qwen-instruct", "glm-4.5", "deepseek-v31"]
    
    results = {}
    
    for model_name in test_models:
        logger.info(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹: {model_name}")
        
        try:
            adapter = get_adapter_by_name(model_name)
            if not adapter:
                logger.warning(f"âš ï¸ æ¨¡å‹ {model_name} ä¸å¯ç”¨")
                results[model_name] = "unavailable"
                continue
            
            # ç®€å•æµ‹è¯•æ¶ˆæ¯
            messages = [
                SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚"),
                HumanMessage(content="è¯·ç®€å•å›å¤'æµ‹è¯•æˆåŠŸ'ã€‚")
            ]
            
            # ä½¿ç”¨ä¿å®ˆçš„å‚æ•°
            kwargs = {
                "temperature": 0.5,
                "max_tokens": 50
            }
            
            response = adapter.invoke(messages, **kwargs)
            logger.info(f"âœ… {model_name} è°ƒç”¨æˆåŠŸ")
            results[model_name] = "success"
            
        except Exception as e:
            logger.error(f"âŒ {model_name} è°ƒç”¨å¤±è´¥: {str(e)}")
            results[model_name] = "failed"
    
    # æ€»ç»“ç»“æœ
    logger.info("\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    for model, result in results.items():
        status_emoji = "âœ…" if result == "success" else "âŒ" if result == "failed" else "âš ï¸"
        logger.info(f"   {status_emoji} {model}: {result}")
    
    return results

def test_parameter_filtering():
    """æµ‹è¯•å‚æ•°è¿‡æ»¤åŠŸèƒ½"""
    logger.info("\nğŸ›¡ï¸ æµ‹è¯•å‚æ•°è¿‡æ»¤åŠŸèƒ½")
    logger.info("=" * 40)
    
    try:
        adapter = get_adapter_by_name("gpt-oss")
        if not adapter:
            logger.error("âŒ æ— æ³•è·å–é€‚é…å™¨")
            return False
        
        # æ•…æ„åŒ…å«ä¸å…¼å®¹çš„å‚æ•°
        problematic_params = {
            "temperature": 0.7,
            "max_tokens": 1000,
            "function_call": "auto",  # GPT-OSSä¸æ”¯æŒ
            "functions": [{"name": "test"}],  # GPT-OSSä¸æ”¯æŒ
            "top_p": 0.9,
            "invalid_param": "should_be_filtered"  # æ— æ•ˆå‚æ•°
        }
        
        logger.info("ğŸ” åŸå§‹å‚æ•°:")
        for key, value in problematic_params.items():
            logger.info(f"   {key}: {value}")
        
        # æµ‹è¯•å‚æ•°è¿‡æ»¤
        if hasattr(adapter, '_filter_model_specific_params'):
            filtered_params = adapter._filter_model_specific_params(problematic_params)
            
            logger.info("\nâœ… è¿‡æ»¤åå‚æ•°:")
            for key, value in filtered_params.items():
                logger.info(f"   {key}: {value}")
            
            # æ˜¾ç¤ºè¢«è¿‡æ»¤çš„å‚æ•°
            filtered_out = set(problematic_params.keys()) - set(filtered_params.keys())
            if filtered_out:
                logger.info(f"\nğŸ›¡ï¸ å·²è¿‡æ»¤çš„å‚æ•°: {list(filtered_out)}")
            else:
                logger.info("\nâš ï¸ æ²¡æœ‰å‚æ•°è¢«è¿‡æ»¤")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ å‚æ•°è¿‡æ»¤æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹å®‰å…¨APIè°ƒç”¨æµ‹è¯•")
    logger.info("=" * 50)
    
    # æµ‹è¯•1: å®‰å…¨çš„GPT-OSSè°ƒç”¨
    success1 = test_safe_gpt_oss_call()
    
    # æµ‹è¯•2: å¤šæ¨¡å‹å®‰å…¨è°ƒç”¨
    results2 = test_multiple_models_safely()
    
    # æµ‹è¯•3: å‚æ•°è¿‡æ»¤åŠŸèƒ½
    success3 = test_parameter_filtering()
    
    # æœ€ç»ˆæ€»ç»“
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“‹ æœ€ç»ˆæµ‹è¯•æ€»ç»“")
    logger.info("=" * 50)
    
    logger.info(f"GPT-OSSå®‰å…¨è°ƒç”¨: {'âœ… æˆåŠŸ' if success1 else 'âŒ å¤±è´¥'}")
    logger.info(f"å¤šæ¨¡å‹æµ‹è¯•: {len([r for r in results2.values() if r == 'success'])}/{len(results2)} æˆåŠŸ")
    logger.info(f"å‚æ•°è¿‡æ»¤æµ‹è¯•: {'âœ… æˆåŠŸ' if success3 else 'âŒ å¤±è´¥'}")
    
    if success1 and success3:
        logger.info("\nğŸ‰ å®‰å…¨APIè°ƒç”¨æœºåˆ¶éªŒè¯æˆåŠŸ!")
        logger.info("ğŸ’¡ å»ºè®®: åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ä¸“ç”¨é€‚é…å™¨æ¥é¿å…500é”™è¯¯")
    else:
        logger.warning("\nâš ï¸ æŸäº›æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")

if __name__ == "__main__":
    main()