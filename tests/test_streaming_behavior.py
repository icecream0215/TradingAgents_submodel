#!/usr/bin/env python3
"""
æµ‹è¯•ç¬¬ä¸‰æ–¹OpenAI APIçš„å®é™…è¯·æ±‚è¡Œä¸º
éªŒè¯æ˜¯å¦çœŸçš„åœ¨å‘é€æµå¼è¯·æ±‚
"""

import sys
import os
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_third_party_openai_request():
    """æµ‹è¯•ç¬¬ä¸‰æ–¹OpenAIé€‚é…å™¨çš„å®é™…è¯·æ±‚è¡Œä¸º"""
    print("ğŸ” æµ‹è¯•ç¬¬ä¸‰æ–¹OpenAI APIçš„è¯·æ±‚è¡Œä¸º")
    print("=" * 50)
    
    try:
        from tradingagents.llm_adapters.third_party_openai import ThirdPartyOpenAI
        from langchain_core.messages import HumanMessage
        
        # æ£€æŸ¥æ˜¯å¦æœ‰APIå¯†é’¥
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âš ï¸ æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨æµ‹è¯•å¯†é’¥")
            api_key = "test-key"
        
        print(f"ğŸ”§ åˆ›å»ºç¬¬ä¸‰æ–¹OpenAIé€‚é…å™¨...")
        llm = ThirdPartyOpenAI(
            model="gpt-3.5-turbo", 
            api_key=api_key,
            base_url="https://llm.submodel.ai/v1",
            temperature=0.7,
            max_tokens=50
        )
        
        # æ£€æŸ¥åˆå§‹åŒ–æ—¶çš„æµå¼è®¾ç½®
        print(f"ğŸ“‹ é€‚é…å™¨é…ç½®æ£€æŸ¥:")
        print(f"   streamingå±æ€§: {getattr(llm, 'streaming', 'N/A')}")
        print(f"   model_kwargs: {getattr(llm, 'model_kwargs', {})}")
        
        # æ£€æŸ¥_direct_api_callæ–¹æ³•çš„é»˜è®¤å‚æ•°
        import inspect
        sig = inspect.signature(llm._direct_api_call)
        stream_param = sig.parameters.get('stream')
        if stream_param:
            print(f"   _direct_api_callçš„streamé»˜è®¤å€¼: {stream_param.default}")
        
        # æ¨¡æ‹Ÿè¯·æ±‚æ•°æ®æ„å»ºè¿‡ç¨‹ï¼ˆä¸å®é™…å‘é€è¯·æ±‚ï¼‰
        print(f"\nğŸŒ æ¨¡æ‹Ÿè¯·æ±‚æ•°æ®æ„å»º...")
        
        # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†
        messages = [HumanMessage(content="æµ‹è¯•æ¶ˆæ¯")]
        api_messages = []
        for msg in messages:
            api_messages.append({
                'role': 'user',
                'content': msg.content
            })
        
        # æ¨¡æ‹Ÿè¯·æ±‚æ•°æ®æ„å»º
        model_name = getattr(llm, 'model_name', 'gpt-3.5-turbo')
        temperature = getattr(llm, 'temperature', 0.7)
        max_tokens = getattr(llm, 'max_tokens', 50)
        
        # æ£€æŸ¥_direct_api_callçš„é»˜è®¤è¡Œä¸º
        request_data_stream = {
            'model': model_name,
            'messages': api_messages,
            'temperature': temperature,
            'stream': True  # é»˜è®¤æµå¼
        }
        
        request_data_non_stream = {
            'model': model_name,
            'messages': api_messages,
            'temperature': temperature,
            'stream': False  # éæµå¼
        }
        
        if max_tokens and max_tokens > 0:
            request_data_stream['max_tokens'] = max_tokens
            request_data_non_stream['max_tokens'] = max_tokens
        
        print(f"ğŸ“¤ æµå¼è¯·æ±‚æ•°æ®:")
        print(f"   {json.dumps(request_data_stream, indent=2, ensure_ascii=False)}")
        
        print(f"ğŸ“¤ éæµå¼è¯·æ±‚æ•°æ®:")
        print(f"   {json.dumps(request_data_non_stream, indent=2, ensure_ascii=False)}")
        
        # æ£€æŸ¥å®é™…çš„è¯·æ±‚è·¯å¾„
        print(f"\nğŸ”„ è¯·æ±‚è·¯å¾„åˆ†æ:")
        
        # æ£€æŸ¥æ˜¯å¦ä¼šä½¿ç”¨LangChainçš„æ ‡å‡†æ–¹æ³•è¿˜æ˜¯ç›´æ¥APIè°ƒç”¨
        print(f"   1. é¦–å…ˆå°è¯•: super()._generate() - LangChainæ ‡å‡†æ–¹æ³•")
        print(f"   2. å¦‚æœå¤±è´¥: _direct_api_call() - ç›´æ¥APIæ–¹æ³•")
        
        # æ£€æŸ¥_direct_api_callçš„æµå¼è¡Œä¸º
        print(f"   _direct_api_callé»˜è®¤ä½¿ç”¨æµå¼è¯·æ±‚: stream=True")
        print(f"   æµå¼å“åº”å¤„ç†: response.iter_lines() + SSEè§£æ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_openai_compatible_base():
    """æµ‹è¯•OpenAIå…¼å®¹åŸºç±»çš„æµå¼è®¾ç½®"""
    print("\nğŸ” æµ‹è¯•OpenAIå…¼å®¹åŸºç±»çš„æµå¼è®¾ç½®")
    print("=" * 50)
    
    try:
        from tradingagents.llm_adapters.openai_compatible_base import ChatDeepSeekOpenAI
        
        # ä½¿ç”¨æµ‹è¯•APIå¯†é’¥
        os.environ["DEEPSEEK_API_KEY"] = "test-key"
        
        print(f"ğŸ”§ åˆ›å»ºOpenAIå…¼å®¹é€‚é…å™¨...")
        llm = ChatDeepSeekOpenAI(
            model="deepseek-chat",
            temperature=0.7,
            max_tokens=50
        )
        
        # æ£€æŸ¥æµå¼è®¾ç½®
        print(f"ğŸ“‹ é€‚é…å™¨é…ç½®æ£€æŸ¥:")
        print(f"   streamingå±æ€§: {getattr(llm, 'streaming', 'N/A')}")
        print(f"   model_kwargs: {getattr(llm, 'model_kwargs', {})}")
        
        # æ£€æŸ¥åˆå§‹åŒ–æ—¥å¿—ä¸­æ˜¯å¦æ˜¾ç¤ºæµå¼è¯·æ±‚å·²å¯ç”¨
        print(f"   ä»åˆå§‹åŒ–æ—¥å¿—å¯è§: 'æµå¼è¯·æ±‚: å·²å¯ç”¨'")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ åˆ†æç¬¬ä¸‰æ–¹OpenAI APIçš„æµå¼è¯·æ±‚è¡Œä¸º")
    
    test1_success = test_third_party_openai_request()
    test2_success = test_openai_compatible_base()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š æµå¼è¯·æ±‚è¡Œä¸ºåˆ†æç»“æœ")
    print("=" * 50)
    
    print("âœ… ç¬¬ä¸‰æ–¹OpenAIé€‚é…å™¨ (ThirdPartyOpenAI):")
    print("   - åˆå§‹åŒ–æ—¶è®¾ç½®: streaming=True, stream=True")
    print("   - _direct_api_callé»˜è®¤: stream=True")
    print("   - è¯·æ±‚æ•°æ®åŒ…å«: 'stream': True")
    print("   - å“åº”å¤„ç†: response.iter_lines() + SSEè§£æ")
    
    print("\nâœ… OpenAIå…¼å®¹åŸºç±» (ChatDeepSeekOpenAI):")
    print("   - åˆå§‹åŒ–æ—¶è®¾ç½®: streaming=True, stream=True")
    print("   - ç›´æ¥ä¼ é€’æ‰€æœ‰å‚æ•°ï¼Œä¸è¿›è¡Œè¿‡æ»¤")
    
    print(f"\nğŸ¯ ç»“è®º:")
    print(f"æ˜¯çš„ï¼Œç°åœ¨å¯¹ç¬¬ä¸‰æ–¹OpenAI APIå‘é€çš„æ˜¯ **æµå¼è¯·æ±‚**")
    print(f"")
    print(f"ğŸ“‹ æŠ€æœ¯ç»†èŠ‚:")
    print(f"1. åˆå§‹åŒ–æ—¶è‡ªåŠ¨è®¾ç½® streaming=True å’Œ stream=True")
    print(f"2. _direct_api_callæ–¹æ³•é»˜è®¤ä½¿ç”¨ stream=True")
    print(f"3. å‘é€çš„è¯·æ±‚æ•°æ®åŒ…å« 'stream': true")
    print(f"4. ä½¿ç”¨ requests.post(..., stream=True) æ¥æ”¶å“åº”")
    print(f"5. é€šè¿‡ response.iter_lines() å¤„ç†SSEæµå¼å“åº”")
    print(f"6. è§£ææ¯ä¸ªchunkä¸­çš„deltaå†…å®¹")
    
    print(f"\nâš ï¸ ä½†è¦æ³¨æ„:")
    print(f"- å¦‚æœLangChainæ ‡å‡†æ–¹æ³•å¤±è´¥ï¼Œæ‰ä¼šä½¿ç”¨_direct_api_call")
    print(f"- LangChainæ ‡å‡†æ–¹æ³•çš„æµå¼è¡Œä¸ºå–å†³äºå…¶å†…éƒ¨å®ç°")
    print(f"- å®é™…çš„æµå¼æ•ˆæœè¿˜å–å†³äºAPIæœåŠ¡ç«¯çš„æ”¯æŒ")

if __name__ == "__main__":
    main()