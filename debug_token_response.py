#!/usr/bin/env python3
"""
è°ƒè¯•Tokenå“åº”ç»“æ„çš„è„šæœ¬
æŸ¥çœ‹LLMå“åº”ä¸­æ˜¯å¦åŒ…å«tokenç”¨é‡ä¿¡æ¯
"""

import os
import sys
import time
import json
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from tradingagents.llm_adapters.third_party_openai import ThirdPartyOpenAI
from tradingagents.utils.logging_manager import get_logger
from langchain_core.messages import HumanMessage, SystemMessage

logger = get_logger('debug')

def load_env_config():
    """åŠ è½½ç¯å¢ƒé…ç½®"""
    from dotenv import load_dotenv
    env_file = Path(__file__).parent / ".env"
    if env_file.exists():
        load_dotenv(env_file, override=True)
        logger.info("âœ… ç¯å¢ƒé…ç½®åŠ è½½æˆåŠŸ")
    else:
        logger.warning("âš ï¸ .envæ–‡ä»¶æœªæ‰¾åˆ°")

def debug_llm_response():
    """è°ƒè¯•LLMå“åº”ç»“æ„"""
    logger.info("ğŸ” è°ƒè¯•LLMå“åº”ç»“æ„...")
    
    # è·å–APIé…ç½®
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = "https://llm.submodel.ai/v1"
    
    if not api_key:
        logger.error("âŒ æœªé…ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        return False
    
    try:
        # åˆ›å»ºThirdPartyOpenAIé€‚é…å™¨
        logger.info(f"ğŸš€ åˆå§‹åŒ–ThirdPartyOpenAIé€‚é…å™¨...")
        
        llm = ThirdPartyOpenAI(
            model="Qwen/Qwen3-235B-A22B-Instruct-2507",
            api_key=api_key,
            base_url=base_url,
            temperature=0.7,
            max_tokens=200
        )
        
        # ç”Ÿæˆå”¯ä¸€ä¼šè¯ID
        session_id = f"debug_test_{int(time.time())}"
        logger.info(f"ğŸ“ ä¼šè¯ID: {session_id}")
        
        # æµ‹è¯•æ¶ˆæ¯
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆã€‚"),
            HumanMessage(content="ç®€å•åˆ†æä¸€ä¸‹èŒ…å°è‚¡ç¥¨ï¼Œä¸è¶…è¿‡30å­—ã€‚")
        ]
        
        logger.info(f"ğŸš€ å‘é€æµ‹è¯•è¯·æ±‚...")
        
        # è°ƒç”¨LLM
        response = llm.invoke(
            messages,
            session_id=session_id,
            analysis_type="debug_test"
        )
        
        logger.info(f"âœ… æ”¶åˆ°å“åº”:")
        logger.info(f"   å†…å®¹: {response.content[:100]}{'...' if len(response.content) > 100 else ''}")
        
        # è¯¦ç»†æ£€æŸ¥å“åº”ç»“æ„
        logger.info(f"ğŸ” å“åº”ç»“æ„åˆ†æ:")
        logger.info(f"   å“åº”ç±»å‹: {type(response)}")
        logger.info(f"   å“åº”å±æ€§: {dir(response)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰llm_outputå±æ€§
        if hasattr(response, 'llm_output'):
            logger.info(f"   llm_outputå­˜åœ¨: {response.llm_output}")
            if response.llm_output:
                logger.info(f"   llm_outputå†…å®¹: {json.dumps(response.llm_output, indent=2, ensure_ascii=False)}")
                if 'token_usage' in response.llm_output:
                    logger.info(f"   token_usage: {response.llm_output['token_usage']}")
                else:
                    logger.warning(f"   âš ï¸ llm_outputä¸­æ²¡æœ‰token_usageå­—æ®µ")
            else:
                logger.warning(f"   âš ï¸ llm_outputä¸ºç©ºæˆ–None")
        else:
            logger.warning(f"   âš ï¸ å“åº”ä¸­æ²¡æœ‰llm_outputå±æ€§")
        
        # æ£€æŸ¥å…¶ä»–å¯èƒ½åŒ…å«tokenä¿¡æ¯çš„å±æ€§
        possible_attrs = ['usage', 'token_usage', 'generation_info', 'additional_kwargs']
        for attr in possible_attrs:
            if hasattr(response, attr):
                value = getattr(response, attr)
                logger.info(f"   {attr}: {value}")
        
        # å¦‚æœå“åº”æœ‰generationså±æ€§
        if hasattr(response, 'generations'):
            logger.info(f"   generationsæ•°é‡: {len(response.generations)}")
            for i, gen in enumerate(response.generations):
                logger.info(f"   generation[{i}] ç±»å‹: {type(gen)}")
                logger.info(f"   generation[{i}] å±æ€§: {dir(gen)}")
                if hasattr(gen, 'generation_info'):
                    logger.info(f"   generation[{i}].generation_info: {gen.generation_info}")
        
        # ç›´æ¥æµ‹è¯•åŸå§‹APIè°ƒç”¨
        logger.info(f"ğŸŒ æµ‹è¯•ç›´æ¥APIè°ƒç”¨è·å–tokenä¿¡æ¯...")
        test_direct_api_call(api_key, base_url, messages)
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ è°ƒè¯•æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False

def test_direct_api_call(api_key, base_url, messages):
    """ç›´æ¥æµ‹è¯•APIè°ƒç”¨è·å–tokenä¿¡æ¯"""
    import requests
    
    try:
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        api_messages = []
        for msg in messages:
            if hasattr(msg, 'type'):
                role = 'user' if msg.type == 'human' else 'assistant'
            else:
                role = 'user'
            api_messages.append({
                'role': role,
                'content': msg.content
            })
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        request_data = {
            'model': 'Qwen/Qwen3-235B-A22B-Instruct-2507',
            'messages': api_messages,
            'temperature': 0.7,
            'max_tokens': 200,
            'stream': False  # ä½¿ç”¨éæµå¼è¯·æ±‚ä»¥è·å–å®Œæ•´å“åº”
        }
        
        # è¯·æ±‚å¤´
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}'
        }
        
        api_url = f"{base_url}/chat/completions"
        logger.info(f"ğŸŒ ç›´æ¥APIè°ƒç”¨: {api_url}")
        
        response = requests.post(
            api_url,
            headers=headers,
            json=request_data,
            timeout=120
        )
        
        logger.info(f"ğŸ“¡ APIå“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            logger.info(f"ğŸ“Š å®Œæ•´APIå“åº”ç»“æ„:")
            logger.info(f"{json.dumps(data, indent=2, ensure_ascii=False)}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰usageå­—æ®µ
            if 'usage' in data:
                usage = data['usage']
                logger.info(f"âœ… æ‰¾åˆ°usageå­—æ®µ:")
                logger.info(f"   prompt_tokens: {usage.get('prompt_tokens', 'N/A')}")
                logger.info(f"   completion_tokens: {usage.get('completion_tokens', 'N/A')}")
                logger.info(f"   total_tokens: {usage.get('total_tokens', 'N/A')}")
                return usage
            else:
                logger.warning(f"âš ï¸ APIå“åº”ä¸­æ²¡æœ‰usageå­—æ®µ")
        else:
            logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
            
    except Exception as e:
        logger.error(f"âŒ ç›´æ¥APIè°ƒç”¨å¤±è´¥: {e}")
    
    return None

def main():
    """ä¸»è°ƒè¯•å‡½æ•°"""
    logger.info("ğŸ” Tokenå“åº”ç»“æ„è°ƒè¯•")
    logger.info("=" * 50)
    
    # 1. åŠ è½½ç¯å¢ƒé…ç½®
    load_env_config()
    
    # 2. è°ƒè¯•LLMå“åº”
    success = debug_llm_response()
    
    # 3. æ€»ç»“
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“‹ è°ƒè¯•æ€»ç»“:")
    
    if success:
        logger.info("âœ… è°ƒè¯•å®Œæˆï¼Œè¯·æŸ¥çœ‹ä¸Šé¢çš„å“åº”ç»“æ„åˆ†æ")
    else:
        logger.error("âŒ è°ƒè¯•å¤±è´¥")
    
    logger.info("\nğŸ’¡ å¦‚æœAPIå“åº”ä¸­æœ‰usageå­—æ®µä½†LangChainæ²¡æœ‰æå–ï¼Œ")
    logger.info("   éœ€è¦ä¿®æ”¹ThirdPartyOpenAIé€‚é…å™¨æ¥ç›´æ¥è§£æAPIå“åº”")

if __name__ == "__main__":
    main()